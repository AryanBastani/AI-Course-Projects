{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">University of Tehran</h1>\n",
    "<h2 align=\"center\">CA2</h2>\n",
    "<h3 align=\"center\">Aryan Bastani</h3>\n",
    "<h3 align=\"center\">810100088</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "</br>\n",
    "<h1 align=\"center\">Hidden Markov Models</h1>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project involves the implementation and analysis of a Hidden Markov Model (HMM) for audio signal processing. The HMM is a statistical model in which the system being modeled is assumed to be a Markov process with hidden states. The challenge lies in determining the hidden states based on the observable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "from python_speech_features import mfcc as Mfcc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.stats import multivariate_normal\n",
    "import sklearn.metrics as sk_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"0\",\"1\",\"2\",\"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "numbersDataPath = [f\".\\Data\\{numbers[0]}\\*.wav\", f\".\\Data\\{numbers[1]}\\*.wav\",\n",
    "                   f\".\\Data\\{numbers[2]}\\*.wav\", f\".\\Data\\{numbers[3]}\\*.wav\",\n",
    "                   f\".\\Data\\{numbers[4]}\\*.wav\", f\".\\Data\\{numbers[5]}\\*.wav\",\n",
    "                   f\".\\Data\\{numbers[6]}\\*.wav\", f\".\\Data\\{numbers[7]}\\*.wav\",\n",
    "                   f\".\\Data\\{numbers[8]}\\*.wav\", f\".\\Data\\{numbers[9]}\\*.wav\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "### 1. do you think data segmentation is useful for this project? Why?\n",
    "\n",
    "\n",
    "Given the dataset and the use of Hidden Markov Models (HMMs), data segmentation can indeed be an appropriate approach. Here‚Äôs why:\n",
    "\n",
    "Sequential Data Modeling: HMMs are well-suited for modeling sequential data, such as speech signals, time series, or natural language sequences. By segmenting the data, we can capture temporal dependencies and transitions between hidden states effectively.\n",
    "State Transitions: In an HMM, each hidden state corresponds to a specific segment of the data. For example, in speech recognition, different states might represent phonemes or words. By segmenting the data, we create a natural mapping to these states.\n",
    "Training Efficiency: Smaller segments facilitate more efficient training. We can focus on local patterns within each segment, leading to faster convergence during model training.\n",
    "Noise Isolation: Segmentation helps identify noisy or irrelevant portions of the data. By isolating these segments, we improve the quality of the training data.\n",
    "In summary, data segmentation aligns well with the principles of HMMs and can enhance their performance. However, it‚Äôs essential to choose appropriate segment boundaries and consider the trade-offs based on the specific problem and dataset .\n",
    "\n",
    "\n",
    "### 2. Extracting Features and differences between them\n",
    "\n",
    "In the realm of artificial intelligence and machine learning, **feature extraction** and **feature selection** play pivotal roles. These steps significantly impact the performance of our models. Let's delve into some essential audio features and explore their relationships:\n",
    "\n",
    "- #### Mel-Frequency Cepstral Coefficients (MFCC)\n",
    "    - **Definition**: MFCCs represent the short-term power spectrum of a sound signal.\n",
    "    - **Purpose**: They capture spectral characteristics, emphasizing perceptually relevant features.\n",
    "    - **Extraction Process**:\n",
    "        - Compute the power spectrum.\n",
    "        - Apply the Mel filterbank to obtain Mel-scale frequencies.\n",
    "        - Take the logarithm of filterbank energies.\n",
    "        - Apply the Discrete Cosine Transform (DCT) to yield MFCCs.\n",
    "    - **Applications**: Speech recognition, speaker identification, and music genre classification.\n",
    "    - **Relation to Other Features**: Often used as input features for other models due to their effectiveness in capturing spectral information.\n",
    "\n",
    "- #### Zero Crossing Rate\n",
    "    - **Definition**: Counts zero crossings in the audio signal.\n",
    "    - **Purpose**: Provides insights into temporal variations, indicating noisiness or silence.\n",
    "    - **Extraction Process**:\n",
    "        - Calculate the sign of audio samples.\n",
    "        - Count zero crossings.\n",
    "    - **Applications**: Voice activity detection, audio segmentation, and noise classification.\n",
    "    - **Relation to Other Features**: Complementary to features like MFCCs, focusing on temporal aspects.\n",
    "\n",
    "- #### Mel-Spectrogram\n",
    "    - **Definition**: Represents the power spectral density in Mel-scale frequencies.\n",
    "    - **Purpose**: Combines spectrogram and Mel-scale filtering benefits.\n",
    "    - **Extraction Process**:\n",
    "        - Compute Short-Time Fourier Transform (STFT).\n",
    "        - Apply Mel filterbank to STFT magnitude.\n",
    "    - **Applications**: Music genre classification, speech recognition, and sound event detection.\n",
    "    - **Relation to Other Features**: Linked to MFCCs due to shared Mel-scale filtering.\n",
    "\n",
    "-   #### Chroma Features\n",
    "    - **Definition**: Represents the 12 distinct pitch classes (notes) in music.\n",
    "    - **Purpose**: Captures harmonic content and tonality.\n",
    "    - **Extraction Process**:\n",
    "        - Compute STFT of the audio signal.\n",
    "        - Sum magnitudes of STFT bins corresponding to each pitch class.\n",
    "    - **Applications**: Music genre classification, chord recognition, and melody extraction.\n",
    "    - **Relation to Other Features**: Complementary to features like MFCCs and spectrogram-based features.\n",
    "\n",
    "Remember that feature choice depends on the task and data characteristics. Intelligently combining these features enhances model performance. üéßüîç"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
